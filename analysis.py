#!/usr/bin/python

# Project Clearwater - IMS in the Cloud
# Copyright (C) 2016 Metaswitch Networks Ltd
#
# This program is free software: you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation, either version 3 of the License, or (at your
# option) any later version, along with the "Special Exception" for use of
# the program along with SSL, set forth below. This program is distributed
# in the hope that it will be useful, but WITHOUT ANY WARRANTY;
# without even the implied warranty of MERCHANTABILITY or FITNESS FOR
# A PARTICULAR PURPOSE.  See the GNU General Public License for more
# details. You should have received a copy of the GNU General Public
# License along with this program.  If not, see
# <http://www.gnu.org/licenses/>.
#
# The author can be reached by email at clearwater@metaswitch.com or by
# post at Metaswitch Networks Ltd, 100 Church St, Enfield EN2 6BQ, UK
#
# Special Exception
# Metaswitch Networks Ltd  grants you permission to copy, modify,
# propagate, and distribute a work formed by combining OpenSSL with The
# Software, or a work derivative of such a combination, even if such
# copying, modification, propagation, or distribution would otherwise
# violate the terms of the GPL. You must comply with the GPL in all
# respects for all of the code used other than OpenSSL.
# "OpenSSL" means OpenSSL toolkit software distributed by the OpenSSL
# Project and licensed under the OpenSSL Licenses, or a work based on such
# software and licensed under the OpenSSL Licenses.
# "OpenSSL Licenses" means the OpenSSL License and Original SSLeay License
# under which the OpenSSL Project distributes the OpenSSL toolkit software,
# as those licenses appear in the file LICENSE-OPENSSL.

"""
This script analyses two directories, a baseline directory and a new directory,
which contain performance data generated by perfrun.sh.

It compares the system-wide CPU usage, the CPU usage of sprout, homestead and
chronos, and the top 15 processes by total CPU usage.

"""

from glob import glob
from scipy.stats import ks_2samp
import argparse

def extract_sar_data(sar_lines):
    """Utility function - turns sar output into a dict of CPU stats"""
    time, cpus, usr, nice, sys, iowait, steal, idle = sar_lines[-1].split()
    return {"usr": float(usr), "nice": float(nice), "sys": float(sys), "iowait": float(iowait)}

def extract_pidstat_data(procname, pidstat_lines):
    """Utility function - reads pidstat output, finds the line corresponding to
    a particular process, and returns a dict of CPU stats"""

    # The top 3 lines are in a different format - skip them.
    for proc_line in pidstat_lines[3:]:
        time, uid, pid, usr, sys, guest, total, cpu_num, process = proc_line.split()
        if process == procname:
            return {"time": time, "uid": uid, "pid": pid, "usr": float(usr), "sys": float(sys), "guest": float(guest), "total": float(total), "cpu_num": cpu_num, "process": process}

def compile_pidstat_data(d, pidstat_lines):
    for proc_line in pidstat_lines[3:]:
        time, uid, pid, usr, sys, guest, total, cpu_num, process = proc_line.split()
        if process not in d:
            d[process] = []
        d[process].append(float(total))


def extract_data(directory):
    ret = {
            'userspace': [],
            'nice': [],
            'system': [],
            'iowait': [],
            'sprout': [],
            'homestead': [],
            'chronos': [],
            'pidstats': {}
            }

    sar_files = glob(directory+"/*/sar.out")
    pidstat_files = glob(directory+"/*/pidstat.out")


    # Iterate over the sar files and build up a list of sprout/homestead/ralf
    # CPU statistics for this run
    for p in pidstat_files:
        with open(p) as f:
            l = f.readlines()

            for component in ["sprout", "homestead", "chronos"]:
                d = extract_pidstat_data(component, l)
                ret[component].append(d['total'])
            
            compile_pidstat_data(ret['pidstats'], l)

    # Average the pidstat data across all the output files and calculate the
    # 15 most CPU-intensive processes in this test run.
    for k, v in ret['pidstats'].iteritems():
        ret['pidstats'][k] = sum(v) / len(v)

    top_pidstats = sorted(ret['pidstats'].keys(),
            key=(lambda x: ret['pidstats'][x]), reverse=True)

    ret['pidstats'] = [(k, ret['pidstats'][k]) for k in top_pidstats[:15]]

    # Iterate over the sar files and build up a list of CPU statistics for this run
    for s in sar_files:
        with open(s) as f:
            l = f.readlines()
            d = extract_sar_data(l)
            ret['userspace'].append(d['usr'])
            ret['nice'].append(d['nice'])
            ret['system'].append(d['sys'])
            ret['iowait'].append(d['iowait'])

    return ret

def compare(description, baseline_samples, new_samples):
    """Compares two lists of samples, printing a mean, a percentage difference between them, and the K-S test p-value"""
    baseline_mean = sum(baseline_samples) / len(baseline_samples)
    new_mean = sum(new_samples) / len(new_samples)
    diff = 0
    if baseline_mean:
        diff = (new_mean - baseline_mean) / baseline_mean
    d, prob = ks_2samp(baseline_samples, new_samples)
    print("{}: Means are {} and {}, {:2.2f}% change - {:2.2f}% chance these are from the same performance profile".
               format(description, baseline_mean, new_mean, diff*100, prob*100))

def compare_two_runs(baseline_dir, new_dir):
    a = extract_data(baseline_dir)
    b = extract_data(new_dir)

    for k in ['sprout', 'homestead', 'chronos', 'userspace', 'system', 'iowait', 'nice']:
            compare(k, a[k], b[k])

    print "\n\nTop 15 processes from baseline run:\n"

    for k, v in a['pidstats']:
            print "{}: {:2.2f}".format(k, v)

    print "\n\nTop 15 processes from new run:\n"

    for k, v in b['pidstats']:
            print "{}: {:2.2f}".format(k, v)

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--baseline')
    parser.add_argument('--new')

    args = parser.parse_args()

    compare_two_runs(args.baseline, args.new)

if __name__ == "__main__":
    main()
